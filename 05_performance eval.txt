1Ô∏è‚É£ Accuracy et cross-validation

Logistic Regression : 66,7‚ÄØ%

Naive Bayes : 62,2‚ÄØ%

SVM (Linear) : 68,1‚ÄØ% ‚Üí meilleur mod√®le sur cross-validation

‚úÖ Conclusion : les performances sont acceptables pour un petit dataset, mais pas exceptionnelles. Elles refl√®tent le fait que le dataset est petit, probablement d√©s√©quilibr√©, et que la g√©n√©ration des labels est automatique via TextBlob-FR (donc bruit√©e).

2Ô∏è‚É£ Performance sur tout le dataset

Accuracy = 97,5‚ÄØ%

F1-score (weighted) = 97,1‚ÄØ%

Probl√®me : ces valeurs sont trompeuses, car le dataset est petit et les classes sont d√©s√©quilibr√©es :

Negative : 7

Neutral : 74

Positive : 120

Le mod√®le pr√©dit tr√®s bien les classes majoritaires (Neutral/Positive), mais mal la classe Minoritaire (Negative ‚Üí f1-score 0,60).

‚úÖ Conclusion : le mod√®le est fort sur les avis majoritaires, mais faible pour les avis n√©gatifs, donc la performance globale ‚Äúaccuracy‚Äù n‚Äôest pas un indicateur fiable seul.
alors on a utilis√© f1

3Ô∏è‚É£ Justification des metrics

Accuracy : simple et intuitive, mais inutilement √©lev√©e si classes d√©s√©quilibr√©es.

F1-score (weighted) : combine pr√©cision et rappel, pond√©r√© par support ‚Üí mieux pour dataset d√©s√©quilibr√©.

Classification report : donne pr√©cision, rappel et f1-score par classe, indispensable pour voir la performance sur la classe minoritaire (Negative).


üîπ Synth√®se

Le SVM lin√©aire est le meilleur mod√®le pour ce dataset.

Les metrics pond√©r√©es (F1-score weighted) sont plus fiables que l‚Äôaccuracy brute.

Les classes minoritaires (Negative) restent un d√©fi.

Pour am√©liorer :

Plus de donn√©es annot√©es ou manuellement corrig√©es.

Balance des classes (oversampling / undersampling).

Essayer des embeddings plus riches (Word2Vec, FastText, CamemBERT pour fran√ßais).